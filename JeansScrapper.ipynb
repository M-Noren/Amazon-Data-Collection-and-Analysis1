{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### This project is meant to serve as an exercise for web scrapping and database creation. We begin with the retrieval of jean reviews from Amazon listings to create a database for future analysis.\n",
    "\n",
    "###### After retrieving the data, we will perform data tranformation to ensure each column's use in Tableau data visualization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# third-party imports\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Fucntion Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### It may be best to refer to the ```main``` function before the following sections for better clarity. \n",
    "###### Obtaining the data we need involves 4 steps:\n",
    "1. Retrieving the html source code\n",
    "2. Dissecting the code for the desired attributes\n",
    "3. Recording the data into a database\n",
    "4. Exporting that database as a .csv file\n",
    " \n",
    "###### These tasks have been implemented in the functions defined below. The ```get_html``` function below takes a search result item and returns the html for its product page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(item):\n",
    "    '''Return the HTML Source Code For An Item'''\n",
    "    # First get the item\n",
    "    atag = item.h2.a\n",
    "    url = 'https://www.amazon.com' + atag.get('href')\n",
    "    \n",
    "    # Get page source for item\n",
    "    driver = webdriver.Chrome(r'C:\\Users\\marti\\Downloads\\chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    item_page = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    return item_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Parameter Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ```get_jean_info``` uses the source code returned from ```get_html``` to retrieve product and review data. Each review is stored in a dictionary object that is then stored in the ```review_collection``` list. There are 8 data points or columns collected by this function:\n",
    " - Product Name\n",
    " - Product Price\n",
    " - Product Brand\n",
    " - Review Rating\n",
    " - Review Title\n",
    " - Review Body\n",
    " - Review Date\n",
    " - Product Size\n",
    "\n",
    "###### With this list of data points, we need only a way to find and collect them. Within the function below, we define the code to navigate through each product page and nested review pages. Before we continue, take a moment to understand how our data is being extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### As an example, the HTML for the page below is used by the ```get_jean_info``` function for data collection. Product name and price are taken right from this page before using the \"see all reviews\" link near the page's end to access the \"Customer Reviews\" page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![item_page](item_page.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![see_all](see_all.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### From this link, the HTML from the \"Customer Reviews\" page is used to assign values for the remaining data points. If a value cannot be found, ```None``` is assigned instead. To ensure a decent amount of reviews are collected for each item, a maximum of 900 pages are searched for customer reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3WKst1_7RKt"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_jean_info(item_page):\n",
    "    '''Obtain all product info for item'''\n",
    "    \n",
    "    # Get product name and price\n",
    "    product_name = item_page.find('span', {'id': 'productTitle'}).text.strip() if item_page.find('span', {'id': 'productTitle'}) else None\n",
    "    price = item_page.find('span', {'id': 'priceblock_ourprice'}).text.strip() if item_page.find('span', {'id': 'priceblock_ourprice'}) else None\n",
    "    \n",
    "    review_collection = []\n",
    "    \n",
    "    for x in range(1, 900):\n",
    "        \n",
    "        if not item_page.find('a', {'data-hook': 'see-all-reviews-link-foot'}):\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        # Get page source for review page\n",
    "        all_reviews = 'https://www.amazon.com' + item_page.find('a', {'data-hook': 'see-all-reviews-link-foot'}).get('href') + f'&pageNumber={x}'\n",
    "        driver.get(all_reviews)\n",
    "        review_page = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "        # Get review data\n",
    "        reviews = review_page.find_all('div', {'data-hook': 'review'})\n",
    "\n",
    "        for i in reviews:\n",
    "            review = {\n",
    "                'product_name': product_name,\n",
    "                'price': price,\n",
    "                'review_rating': float(i.find('i', {'data-hook': 'review-star-rating'}).text.replace('out of 5 stars', '').strip()) if i.find('i', {'data-hook': 'review-star-rating'}) else None,\n",
    "                'review_title': i.find('a', {'data-hook': 'review-title'}).text.strip() if i.find('a', {'data-hook': 'review-title'}) else None,\n",
    "                'review_body': i.find('span', {'data-hook': 'review-body'}).text.strip() if i.find('span', {'data-hook': 'review-body'}) else None,\n",
    "                'review_date': i.find('span', {'data-hook': 'review-date'}).text if i.find('span', {'data-hook': 'review-date'}) else None,\n",
    "                \n",
    "                'size': i.find('a', {'data-hook': 'format-strip'})\n",
    "                .find_all(text=True, recursive=False)[0]\n",
    "                .replace('Size: ', '').strip() if i\n",
    "                .find('a', {'data-hook': 'format-strip'}) else None\n",
    "            }\n",
    "            review_collection.append(review)\n",
    "        \n",
    "        # If there isn't a 'Next page' button, break the loop\n",
    "        if not review_page.find('li', {'class': 'a-last'}):\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "        if not review_page.find('li', {'class': 'a-disabled a-last'}):\n",
    "            pass\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    return review_collection\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Our ```main``` function uses the previous functions to create a csv file of review data. A maximum of eight pages of search results are used here. This process of opening the webdriver, retrieving html, and building the records is very time-consuming (hours worth). This is one of the biggest downsides to using a webdriver over an API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RWkGQrH-7RKv"
   },
   "outputs": [],
   "source": [
    "def main(url):\n",
    "    \"\"\"Run main program routine\"\"\"\n",
    "    \n",
    "    # startup web driver\n",
    "    driver = webdriver.Chrome(r'C:\\Users\\marti\\Downloads\\chromedriver.exe')\n",
    "    \n",
    "    records = []\n",
    "    url += '&page={}'\n",
    "    \n",
    "    # A maximum of 8 pages are searched for product listings\n",
    "    for page in range(1, 8):\n",
    "        driver.get(url.format(page))\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        results = soup.find_all('div', {'data-component-type': 's-search-result'})\n",
    "        \n",
    "        for item in results:\n",
    "            item_page = get_html(item)\n",
    "            records.extend(get_jean_info(item_page))\n",
    "            \n",
    "            \n",
    "    df = pd.DataFrame(records)\n",
    "    df.to_csv('jean_reviews.csv', index=False)\n",
    "    print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nXKzfzc7RKv",
    "outputId": "54df15e1-90d9-4d7b-b9ad-d2b889fb8020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "main('https://www.amazon.com/s?k=mens+jeans&rh=p_72%3A2661618011&s=review-rank&dc&qid=1629410817&rnid=2661617011&ref=sr_pg_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Additional Parameter Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now that we have successfully created an initial dataset, we should preview our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "2qJ7HPoq7RKw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>price</th>\n",
       "      <th>brand</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perry Ellis Men's Skinny Stretch Denim Jeans</td>\n",
       "      <td>$31.29 - $36.17</td>\n",
       "      <td>Perry Ellis</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Worth the money</td>\n",
       "      <td>Excellent product totally recommended</td>\n",
       "      <td>Reviewed in the United States on September 13,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Perry Ellis Men's Skinny Stretch Denim Jeans</td>\n",
       "      <td>$31.29 - $36.17</td>\n",
       "      <td>Perry Ellis</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Comfortable</td>\n",
       "      <td>Great jeans</td>\n",
       "      <td>Reviewed in the United States on May 12, 2021</td>\n",
       "      <td>36W x 30L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perry Ellis Men's Skinny Stretch Denim Jeans</td>\n",
       "      <td>$31.29 - $36.17</td>\n",
       "      <td>Perry Ellis</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fantastique!</td>\n",
       "      <td>Les jeans stretch de cette marque sont fantast...</td>\n",
       "      <td>Reviewed in Canada on March 19, 2020</td>\n",
       "      <td>31W x 32L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perry Ellis Men's Skinny Stretch Denim Jeans</td>\n",
       "      <td>$31.29 - $36.17</td>\n",
       "      <td>Perry Ellis</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Super c贸modos</td>\n",
       "      <td>Super c贸modos</td>\n",
       "      <td>Reviewed in Mexico on April 29, 2021</td>\n",
       "      <td>32W x 34L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perry Ellis Men's Skinny Stretch Denim Jeans</td>\n",
       "      <td>$31.29 - $36.17</td>\n",
       "      <td>Perry Ellis</td>\n",
       "      <td>5.0</td>\n",
       "      <td>cubre mis expectativas</td>\n",
       "      <td>Como esperaba</td>\n",
       "      <td>Reviewed in Mexico on April 2, 2021</td>\n",
       "      <td>34W x 30L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   product_name            price        brand  \\\n",
       "0  Perry Ellis Men's Skinny Stretch Denim Jeans  $31.29 - $36.17  Perry Ellis   \n",
       "1  Perry Ellis Men's Skinny Stretch Denim Jeans  $31.29 - $36.17  Perry Ellis   \n",
       "2  Perry Ellis Men's Skinny Stretch Denim Jeans  $31.29 - $36.17  Perry Ellis   \n",
       "3  Perry Ellis Men's Skinny Stretch Denim Jeans  $31.29 - $36.17  Perry Ellis   \n",
       "4  Perry Ellis Men's Skinny Stretch Denim Jeans  $31.29 - $36.17  Perry Ellis   \n",
       "\n",
       "   review_rating            review_title  \\\n",
       "0            5.0         Worth the money   \n",
       "1            5.0             Comfortable   \n",
       "2            5.0            Fantastique!   \n",
       "3            5.0           Super c贸modos   \n",
       "4            5.0  cubre mis expectativas   \n",
       "\n",
       "                                         review_body  \\\n",
       "0              Excellent product totally recommended   \n",
       "1                                        Great jeans   \n",
       "2  Les jeans stretch de cette marque sont fantast...   \n",
       "3                                      Super c贸modos   \n",
       "4                                      Como esperaba   \n",
       "\n",
       "                                         review_date       size  \n",
       "0  Reviewed in the United States on September 13,...        NaN  \n",
       "1      Reviewed in the United States on May 12, 2021  36W x 30L  \n",
       "2               Reviewed in Canada on March 19, 2020  31W x 32L  \n",
       "3               Reviewed in Mexico on April 29, 2021  32W x 34L  \n",
       "4                Reviewed in Mexico on April 2, 2021  34W x 30L  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('jean_reviews.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "-dKTNPnR7RKx"
   },
   "outputs": [],
   "source": [
    "df_counts = df.product_name.value_counts()\n",
    "p = []\n",
    "for i,r in df_counts.items():\n",
    "    (p.append(i))\n",
    "    \n",
    "count_row = df.shape[0]\n",
    "count_col = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "oRY1BxRk7RKx",
    "outputId": "416fe2e1-0a56-41f5-ff22-a58d4f1432ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Unique Brands:  243\n",
      "Row Count:  277393\n",
      "Column Count:  8\n"
     ]
    }
   ],
   "source": [
    "print(\"#Unique Brands: \", len(p))\n",
    "print(\"Row Count: \", count_row)\n",
    "print(\"Column Count: \", count_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To improve the usability of our dataset, we must create some additional columns and delete duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete duplicate rows\n",
    "df.drop_duplicates(subset=\"review_body\", keep=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts = df.product_name.value_counts()\n",
    "p = []\n",
    "for i,r in df_counts.items():\n",
    "    (p.append(i))\n",
    "    \n",
    "count_row = df.shape[0]\n",
    "count_col = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Unique Brands:  231\n",
      "Row Count:  118865\n",
      "Column Count:  8\n"
     ]
    }
   ],
   "source": [
    "print(\"#Unique Brands: \", len(p))\n",
    "print(\"Row Count: \", count_row)\n",
    "print(\"Column Count: \", count_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price(price):\n",
    "    '''Return jean price as a floating-point type using highest value in range'''\n",
    "    x = re.findall(r\"(?<=\\ - \\$)(\\d+\\.\\d+)\", str(price))\n",
    "    y = x if x else re.findall(r\"(?<=\\$)(.*?\\d+\\.\\d+)\", str(price))\n",
    "    \n",
    "    match = float(y[0]) if y else None\n",
    "    \n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prices'] = df['price'].apply(get_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(date):\n",
    "    '''Return date as datetime object'''\n",
    "    match = re.findall(r'(?<=on )(.*)', date)\n",
    "    \n",
    "    new_date = datetime.strptime(match[0], '%B %d, %Y')\n",
    "    return new_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_dates'] = df['review_date'].apply(get_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_group(price):\n",
    "    '''Return jean price group'''\n",
    "    if (price >= 80):\n",
    "        a = '$80+'\n",
    "    elif (70 <= price < 80):\n",
    "        a = '$70-$80'\n",
    "    elif (60 <= price < 70):\n",
    "        a = '$60-$70'\n",
    "    elif (50 <= price < 60):\n",
    "        a = '$50-$60'\n",
    "    elif (40 <= price < 50):\n",
    "        a = '$40-$50'\n",
    "    elif (30 <= price < 40):\n",
    "        a = '$30-$40'\n",
    "    else:\n",
    "        a = '>$30'\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_groups'] = df['prices'].map(price_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Dataset Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts = df.product_name.value_counts()\n",
    "p = []\n",
    "for i,r in df_counts.items():\n",
    "    (p.append(i))\n",
    "    \n",
    "count_row = df.shape[0]\n",
    "count_col = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Unique Brands:  231\n",
      "Row Count:  118865\n",
      "Column Count:  11\n"
     ]
    }
   ],
   "source": [
    "print(\"#Unique Brands: \", len(p))\n",
    "print(\"Row Count: \", count_row)\n",
    "print(\"Column Count: \", count_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('jean_reviews2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tableau Dashboard\n",
    "###### Here is our completed Tableau dashboard using our final dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tableau Dashboard](dashboard_1.png)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "JeansScrapper-checkpoint.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
